{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-CW8nUEnwLU"
   },
   "source": [
    "## **Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "me_HneP_pkP8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prateek_bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prateek_bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prateek_bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from DataVisualization import DataVisualization\n",
    "from TextCleaning import TextCleaning\n",
    "from CredibilityScoreExtraction import CredibilityScoreExtraction\n",
    "from SentimentFeatureExtraction import SentimentFeatureExtraction\n",
    "from NERFeatureExtraction import NERFeatureExtraction\n",
    "from POSTagFeatureExtraction import POSTagFeatureExtraction\n",
    "from DependencyFeatureExtraction import DependencyFeatureExtraction\n",
    "from MetaFeatureExtraction import MetaFeatureExtraction\n",
    "from Utilities import PCAPercentage, FeatureScaling\n",
    "from sklearn.ensemble import  RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TFs2bjtoJyo"
   },
   "source": [
    "## **Loading Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbvpcMzaWCj7",
    "outputId": "04dc5270-6b2a-406f-94c8-8873e45237a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11524, 14), (1267, 14))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Path of Dataset\n",
    "trainFile = './Dataset/LIAR/train.tsv'\n",
    "testFile = './Dataset/LIAR/test.tsv'\n",
    "valFile = './Dataset/LIAR/valid.tsv'\n",
    "\n",
    "## Name of headers\n",
    "headers = [\"json ID\", \"label\", \"statement\", \"subject\", \"speaker\", \"job title\", \"state\", \"party\", \n",
    "           \"barely true\", \"false\", \"half true\", \"mostly true\", \"pants on fire\", \"los\"]\n",
    "\n",
    "## Loading Data\n",
    "traindata = pd.read_csv(trainFile, delimiter='\\t', encoding='utf-8', names=headers)\n",
    "testdata = pd.read_csv(testFile, delimiter='\\t', encoding='utf-8', names=headers)\n",
    "valdata = pd.read_csv(valFile, delimiter='\\t', encoding='utf-8', names=headers)\n",
    "\n",
    "## concatenate \n",
    "traindata = pd.concat([traindata,valdata])\n",
    "traindata.shape, testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>json ID</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job title</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely true</th>\n",
       "      <th>false</th>\n",
       "      <th>half true</th>\n",
       "      <th>mostly true</th>\n",
       "      <th>pants on fire</th>\n",
       "      <th>los</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      json ID        label                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker             job title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      state       party  barely true  false  half true  mostly true  \\\n",
       "0     Texas  republican          0.0    1.0        0.0          0.0   \n",
       "1  Virginia    democrat          0.0    0.0        1.0          1.0   \n",
       "2  Illinois    democrat         70.0   71.0      160.0        163.0   \n",
       "3       NaN        none          7.0   19.0        3.0          5.0   \n",
       "4   Florida    democrat         15.0    9.0       20.0         19.0   \n",
       "\n",
       "   pants on fire                  los  \n",
       "0            0.0             a mailer  \n",
       "1            0.0      a floor speech.  \n",
       "2            9.0               Denver  \n",
       "3           44.0       a news release  \n",
       "4            2.0  an interview on CNN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMbep5DFacVd"
   },
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TQF7weUnhNU6"
   },
   "outputs": [],
   "source": [
    "## Removing Unncessary information\n",
    "removed_col = ['json ID', 'barely true', 'false', 'half true', 'mostly true', 'pants on fire', 'los', \n",
    "               'party', 'state', 'subject', 'job title']\n",
    "traindata.drop(removed_col, axis='columns', inplace=True)\n",
    "testdata.drop(removed_col, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label        0\n",
       "statement    0\n",
       "speaker      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking for nan\n",
    "traindata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Tjk7yosENgB",
    "outputId": "2c58e6bb-2fcb-4752-f13d-58c818e87806"
   },
   "outputs": [],
   "source": [
    "## fillling speaker nan values\n",
    "traindata.fillna({'speaker':\"None\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WL7oaZMH3Dmw",
    "outputId": "9f89ad3a-4244-4eaf-dcdd-a3ca740159db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Cleaning Starts\n",
      "\t\tText Lowered\n",
      "\t\tPunctuation Removed\n",
      "\t\tStopwords Removed\n",
      "\t\tUrls Removed\n",
      "\t\tHashTags Removed\n",
      "\t\tNumbers Removed\n",
      "\t\tLemmatization Done\n",
      "Text Cleaning Done\n",
      "\n",
      "Text Cleaning Starts\n",
      "\t\tText Lowered\n",
      "\t\tPunctuation Removed\n",
      "\t\tStopwords Removed\n",
      "\t\tUrls Removed\n",
      "\t\tHashTags Removed\n",
      "\t\tNumbers Removed\n",
      "\t\tLemmatization Done\n",
      "Text Cleaning Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_train = TextCleaning(traindata, 'statement').GetDataFrame()\n",
    "cleaned_test = TextCleaning(testdata, 'statement').GetDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYGu9HjckYIP"
   },
   "source": [
    "## **Label Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fIgPPGWWEnCz"
   },
   "outputs": [],
   "source": [
    "y_train = cleaned_train['label']\n",
    "y_test = cleaned_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction And Individual Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC5hAOxHG1Ba"
   },
   "source": [
    "### **Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tw7TUPPNIT5X"
   },
   "outputs": [],
   "source": [
    "x_string_train = cleaned_train['speaker'].map(str) + \" \" + cleaned_train['statement'].map(str)\n",
    "x_string_test = cleaned_test['speaker'].map(str) + \" \" + cleaned_test['statement'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DwXg6f08G5Nd"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_features=4500, ngram_range=(1,1))\n",
    "x_vec_train = vec.fit_transform(x_string_train)\n",
    "x_vec_test = vec.transform(x_string_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PN3du1vdxvO"
   },
   "source": [
    "Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "f4jk1Ts_UBuk"
   },
   "outputs": [],
   "source": [
    "# parameters = {'max_depth':[100,250,500],\n",
    "#               'n_estimators':[100,250,500],\n",
    "#               'min_samples_leaf':[1,5,10],\n",
    "#               'min_samples_split':[5,10,15]\n",
    "#               }\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# scorer = make_scorer(f1_score, average = 'weighted')\n",
    "# clf = GridSearchCV(rf, parameters, scoring=scorer, cv=10)\n",
    "# clf.fit(x_vec_train, y_train)\n",
    "\n",
    "# clf.best_params_\n",
    "\n",
    "# # {'max_depth': 250,\n",
    "# #  'min_samples_leaf': 1,\n",
    "# #  'min_samples_split': 5,\n",
    "# #  'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCjGpruRUNng"
   },
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L92z7RUyqwJ8",
    "outputId": "a85e5db6-c00f-465a-904d-53eb360ef6be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=250, min_samples_split=5, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_vec = RandomForestClassifier(max_depth=250, min_samples_leaf=1, min_samples_split=5, n_estimators=100, random_state=42)\n",
    "rf_vec.fit(x_vec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72AQFSsqJlTK",
    "outputId": "6f0d7f43-4e6d-497d-89da-1d23465858a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9927976397084346\n",
      "Testing Accuracy:  0.2920284135753749\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", rf_vec.score(x_vec_train, y_train))\n",
    "print(\"Testing Accuracy: \", rf_vec.score(x_vec_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4kN-2AHjJsFe"
   },
   "outputs": [],
   "source": [
    "predict_vec_train = pd.DataFrame(rf_vec.predict_proba(x_vec_train), columns=[\"vec-1\",\"vec-2\",\"vec-3\",\"vec-4\",\"vec-5\",\"vec-6\"])\n",
    "predict_vec_test = pd.DataFrame(rf_vec.predict_proba(x_vec_test), columns=[\"vec-1\",\"vec-2\",\"vec-3\",\"vec-4\",\"vec-5\",\"vec-6\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj0bUNIlGPDk"
   },
   "source": [
    "### **NER Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xowo8IpDuZkz",
    "outputId": "1112c8f6-2f0a-48d0-d84e-da93058d447e"
   },
   "outputs": [],
   "source": [
    "# ## Extraction takes time, Run only if have time\n",
    "\n",
    "# x_ner_train = NERFeatureExtraction(traindata, 'statement').GetDataFrame()\n",
    "# x_ner_test = NERFeatureExtraction(testdata, 'statement').GetDataFrame()\n",
    "# x_ner_train.to_csv('./Files/x_ner_train.csv', index = False)\n",
    "# x_ner_test.to_csv('./Files/x_ner_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Saved NER Features\n",
    "x_ner_train = pd.read_csv(\"./Files/x_ner_train.csv\")\n",
    "x_ner_test = pd.read_csv(\"./Files/x_ner_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "ePo5gupvuyrC",
    "outputId": "45de6193-d5ad-45db-bb42-70b670c4236e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>FAC</th>\n",
       "      <th>GPE</th>\n",
       "      <th>NORP</th>\n",
       "      <th>LOC</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>MONEY</th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>ORDINAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PERSON  ORG  FAC  GPE  NORP  LOC  PRODUCT  EVENT  WORK_OF_ART  LAW  \\\n",
       "0       0    0    0    0     0    0        0      0            0    0   \n",
       "1       1    0    0    0     0    0        0      0            0    0   \n",
       "2       3    0    0    1     0    0        0      0            0    0   \n",
       "3       0    0    0    0     0    0        0      0            0    0   \n",
       "4       0    0    0    0     0    0        0      0            0    0   \n",
       "\n",
       "   LANGUAGE  DATE  TIME  PERCENT  MONEY  CARDINAL  QUANTITY  ORDINAL  \n",
       "0         0     0     0        0      0         0         0        1  \n",
       "1         0     0     0        0      0         0         0        0  \n",
       "2         0     0     0        0      0         0         0        0  \n",
       "3         0     0     0        0      0         0         0        0  \n",
       "4         0     0     0        0      0         0         0        0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ner_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLy0HxT4KTYU"
   },
   "source": [
    "Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PZ0a41m4EJh9"
   },
   "outputs": [],
   "source": [
    "# parameters = {'max_depth':[100,250,500],\n",
    "#               'n_estimators':[100,250,500],\n",
    "#               'min_samples_leaf':[1,5,10],\n",
    "#               'min_samples_split':[5,10,15]\n",
    "#               }\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# scorer = make_scorer(f1_score, average = 'weighted')\n",
    "# clf = GridSearchCV(rf, parameters, scoring=scorer, cv=10)\n",
    "# clf.fit(x_meta_train, y_train)\n",
    "\n",
    "# clf.best_params_\n",
    "\n",
    "# # {'max_depth': 250,\n",
    "# #  'min_samples_leaf': 5,\n",
    "# #  'min_samples_split': 5,\n",
    "# #  'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BKUEgN3UUcd"
   },
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MlIJv8SCR-mG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=250, min_samples_leaf=5, min_samples_split=5,\n",
       "                       n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_ner = RandomForestClassifier(max_depth=250, min_samples_leaf=5, min_samples_split=5, n_estimators=250, random_state=42)\n",
    "rf_ner.fit(x_ner_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gDFTun9SQmg",
    "outputId": "43c201f4-db4f-4c28-eba8-f46b14c995b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.29130510239500174\n",
      "Testing Accuracy:  0.24861878453038674\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", rf_ner.score(x_ner_train, y_train))\n",
    "print(\"Testing Accuracy: \", rf_ner.score(x_ner_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **POS Tag Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extraction takes time, Run only if have time\n",
    "\n",
    "# x_pos_train = POSTagFeatureExtraction(traindata, 'statement').GetDataFrame()\n",
    "# x_pos_test = POSTagFeatureExtraction(testdata, 'statement').GetDataFrame()\n",
    "# x_pos_train.to_csv('./Files/x_pos_train.csv', index = False)\n",
    "# x_pos_test.to_csv('./Files/x_pos_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Saved POS Features\n",
    "x_pos_train = pd.read_csv(\"./Files/x_pos_train.csv\")\n",
    "x_pos_test = pd.read_csv(\"./Files/x_pos_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PART</th>\n",
       "      <th>PRON</th>\n",
       "      <th>X</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>SYM</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ADJ  ADP  ADV  AUX  CCONJ  DET  INTJ  NOUN  NUM  PART  PRON  X  PROPN  \\\n",
       "0    2    1    0    0      0    1     0     4    0     0     0  0      2   \n",
       "1    1    3    2    1      0    2     0     5    0     1     1  0      4   \n",
       "2    0    4    0    0      0    2     0     2    0     1     0  0      7   \n",
       "3    2    0    0    1      0    0     0     7    0     1     0  0      0   \n",
       "4    1    2    0    0      0    3     0     3    0     0     0  0      0   \n",
       "\n",
       "   PUNCT  SCONJ  SYM  VERB  SPACE  CONJ  \n",
       "0      2      0    0     2      0     0  \n",
       "1      4      0    0     4      0     0  \n",
       "2      3      0    0     3      0     0  \n",
       "3      1      0    0     1      0     0  \n",
       "4      1      0    0     1      0     0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'max_depth':[100,250,500],\n",
    "#               'n_estimators':[100,250,500],\n",
    "#               'min_samples_leaf':[1,5,10],\n",
    "#               'min_samples_split':[5,10,15]\n",
    "#               }\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# scorer = make_scorer(f1_score, average = 'weighted')\n",
    "# clf = GridSearchCV(rf, parameters, scoring=scorer, cv=10)\n",
    "# clf.fit(x_pos_train, y_train)\n",
    "\n",
    "# clf.best_params_\n",
    "\n",
    "# # {'max_depth': 250,\n",
    "# #  'min_samples_leaf': 1,\n",
    "# #  'min_samples_split': 10,\n",
    "# #  'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=250, min_samples_split=10, n_estimators=250,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pos = RandomForestClassifier(max_depth=250, min_samples_leaf=1, min_samples_split=10, n_estimators=250, random_state=42)\n",
    "rf_pos.fit(x_pos_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9331829225963207\n",
      "Testing Accuracy:  0.23520126282557222\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", rf_pos.score(x_pos_train, y_train))\n",
    "print(\"Testing Accuracy: \", rf_pos.score(x_pos_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dependency Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extraction takes time, Run only if have time\n",
    "\n",
    "# x_dep_train = DependencyFeatureExtraction(traindata, 'statement').GetDataFrame()\n",
    "# x_dep_test = DependencyFeatureExtraction(testdata, 'statement').GetDataFrame()\n",
    "# x_dep_train.to_csv('./Files/x_dep_train.csv', index = False)\n",
    "# x_dep_test.to_csv('./Files/x_dep_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Saved DEP Features\n",
    "x_dep_train = pd.read_csv(\"./Files/x_dep_train.csv\")\n",
    "x_dep_test = pd.read_csv(\"./Files/x_dep_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROOT</th>\n",
       "      <th>acl</th>\n",
       "      <th>acomp</th>\n",
       "      <th>advcl</th>\n",
       "      <th>advmod</th>\n",
       "      <th>agent</th>\n",
       "      <th>amod</th>\n",
       "      <th>appos</th>\n",
       "      <th>attr</th>\n",
       "      <th>aux</th>\n",
       "      <th>...</th>\n",
       "      <th>pobj</th>\n",
       "      <th>poss</th>\n",
       "      <th>preconj</th>\n",
       "      <th>predet</th>\n",
       "      <th>prep</th>\n",
       "      <th>prt</th>\n",
       "      <th>punct</th>\n",
       "      <th>quantmod</th>\n",
       "      <th>relcl</th>\n",
       "      <th>xcomp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROOT  acl  acomp  advcl  advmod  agent  amod  appos  attr  aux  ...  pobj  \\\n",
       "0     1    0      0      0       0      0     2      0     0    0  ...     1   \n",
       "1     2    0      0      1       2      0     1      0     0    1  ...     2   \n",
       "2     1    0      0      0       0      0     0      0     0    1  ...     3   \n",
       "3     1    0      1      0       0      0     1      0     0    1  ...     0   \n",
       "4     1    0      0      0       0      0     1      0     0    0  ...     2   \n",
       "\n",
       "   poss  preconj  predet  prep  prt  punct  quantmod  relcl  xcomp  \n",
       "0     0        0       0     1    0      2         0      0      0  \n",
       "1     0        0       0     2    1      4         0      0      1  \n",
       "2     0        0       0     4    0      3         0      0      1  \n",
       "3     0        0       0     0    0      1         0      0      1  \n",
       "4     1        0       0     2    0      1         0      0      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dep_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'max_depth':[100,250,500],\n",
    "#               'n_estimators':[100,250,500],\n",
    "#               'min_samples_leaf':[1,5,10],\n",
    "#               'min_samples_split':[5,10,15]\n",
    "#               }\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# scorer = make_scorer(f1_score, average = 'weighted')\n",
    "# clf = GridSearchCV(rf, parameters, scoring=scorer, cv=10)\n",
    "# clf.fit(x_dep_train, y_train)\n",
    "\n",
    "# clf.best_params_\n",
    "\n",
    "# # {'max_depth': 250,\n",
    "# #  'min_samples_leaf': 5,\n",
    "# #  'min_samples_split': 10,\n",
    "# #  'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=250, min_samples_leaf=5, min_samples_split=10,\n",
       "                       n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_dep = RandomForestClassifier(max_depth=250, min_samples_leaf=5, min_samples_split=10, n_estimators=250, random_state=42)\n",
    "rf_dep.fit(x_dep_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7628427629295383\n",
      "Testing Accuracy:  0.23362273086029992\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", rf_dep.score(x_dep_train, y_train))\n",
    "print(\"Testing Accuracy: \", rf_dep.score(x_dep_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAPSDmCJg_yh"
   },
   "source": [
    "### **Speaker Credibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l22XZPfaU2a3",
    "outputId": "21c1e0d4-c84b-4e27-c672-7dfeeda7710e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credibility Starts\n",
      "Credibility Done\n",
      "\n",
      "Credibility Starts\n",
      "Credibility Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_speaker_cred_train = CredibilityScoreExtraction(cleaned_train,'speaker').GetDataFrame()\n",
    "x_speaker_cred_test = CredibilityScoreExtraction(cleaned_test,'speaker').GetDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UeN8Dk3PmTsj",
    "outputId": "c4adf09d-13de-4961-d1ac-57c667d5c4c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>half-true</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>pants-fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196809</td>\n",
       "      <td>0.257092</td>\n",
       "      <td>0.264184</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.136525</td>\n",
       "      <td>0.024823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.072165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true  mostly-true  half-true  barely-true     false  pants-fire\n",
       "0  0.000000     0.062500   0.125000     0.187500  0.312500    0.312500\n",
       "1  0.000000     0.062500   0.187500     0.187500  0.250000    0.312500\n",
       "2  0.196809     0.257092   0.264184     0.120567  0.136525    0.024823\n",
       "3  0.023256     0.058140   0.058140     0.116279  0.244186    0.500000\n",
       "4  0.134021     0.195876   0.237113     0.164948  0.195876    0.072165"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_speaker_cred_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stCCd2TkmleV"
   },
   "source": [
    "Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "zVgRbFAXmuG2"
   },
   "outputs": [],
   "source": [
    "# parameters = {'max_depth':[100,250,500],\n",
    "#               'n_estimators':[100,250,400],\n",
    "#               'min_samples_leaf':[1,5,10],\n",
    "#               'min_samples_split':[5,10,15]\n",
    "#               }\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# scorer = make_scorer(f1_score, average = 'weighted')\n",
    "# clf = GridSearchCV(rf, parameters, scoring=scorer, cv=10)\n",
    "# clf.fit(x_speaker_cred_train, y_train)\n",
    "\n",
    "# clf.best_params_\n",
    "\n",
    "# # {'max_depth': 500,\n",
    "# #  'min_samples_leaf': 10,\n",
    "# #  'min_samples_split': 5,\n",
    "# #  'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJw4g4qcnKTO"
   },
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6NmV7HQnJEV",
    "outputId": "d4ca1483-f818-4204-eb72-20052677f5e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=500, min_samples_leaf=10, min_samples_split=5,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_speaker_cred = RandomForestClassifier(max_depth=500, min_samples_leaf=10, min_samples_split=5, n_estimators=100, random_state=42)\n",
    "rf_speaker_cred.fit(x_speaker_cred_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vpD0BljoBUV",
    "outputId": "75e108d2-b7b0-429c-c959-40e8c6536b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.48307879208608123\n",
      "Testing Accuracy:  0.6606156274664562\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", rf_speaker_cred.score(x_speaker_cred_train, y_train))\n",
    "print(\"Testing Accuracy: \", rf_speaker_cred.score(x_speaker_cred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2XbwX24DgEc"
   },
   "source": [
    "### **Sentiment Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ufszGAiKcdP",
    "outputId": "5c877b05-4166-49c7-a24e-8518938e8b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Feature Extraction Starts\n",
      "Sentiment Feature Extraction Done\n",
      "\n",
      "Sentiment Feature Extraction Starts\n",
      "Sentiment Feature Extraction Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_sentiment_train = SentimentFeatureExtraction(traindata, 'statement').GetDataFrame()\n",
    "x_sentiment_test = SentimentFeatureExtraction(testdata, 'statement').GetDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos\n",
       "0  0.115  0.692  0.192\n",
       "1  0.000  0.902  0.098\n",
       "2  0.107  0.687  0.206\n",
       "3  0.000  0.606  0.394\n",
       "4  0.000  1.000  0.000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sentiment_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZxs6ibuhjx9"
   },
   "source": [
    "## **Final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.concat([x_speaker_cred_train,x_pos_train,x_ner_train,x_dep_train,x_sentiment_train], axis = 1)\n",
    "x_test = pd.concat([x_speaker_cred_test,x_pos_test,x_ner_test,x_dep_test,x_sentiment_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>half-true</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>pants-fire</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>AUX</th>\n",
       "      <th>...</th>\n",
       "      <th>predet</th>\n",
       "      <th>prep</th>\n",
       "      <th>prt</th>\n",
       "      <th>punct</th>\n",
       "      <th>quantmod</th>\n",
       "      <th>relcl</th>\n",
       "      <th>xcomp</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196809</td>\n",
       "      <td>0.257092</td>\n",
       "      <td>0.264184</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>0.136525</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.244186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.237113</td>\n",
       "      <td>0.164948</td>\n",
       "      <td>0.195876</td>\n",
       "      <td>0.072165</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       true  mostly-true  half-true  barely-true     false  pants-fire  ADJ  \\\n",
       "0  0.000000     0.062500   0.125000     0.187500  0.312500    0.312500    2   \n",
       "1  0.000000     0.062500   0.187500     0.187500  0.250000    0.312500    1   \n",
       "2  0.196809     0.257092   0.264184     0.120567  0.136525    0.024823    0   \n",
       "3  0.023256     0.058140   0.058140     0.116279  0.244186    0.500000    2   \n",
       "4  0.134021     0.195876   0.237113     0.164948  0.195876    0.072165    1   \n",
       "\n",
       "   ADP  ADV  AUX  ...  predet  prep  prt  punct  quantmod  relcl  xcomp  \\\n",
       "0    1    0    0  ...       0     1    0      2         0      0      0   \n",
       "1    3    2    1  ...       0     2    1      4         0      0      1   \n",
       "2    4    0    0  ...       0     4    0      3         0      0      1   \n",
       "3    0    0    1  ...       0     0    0      1         0      0      1   \n",
       "4    2    0    0  ...       0     2    0      1         0      0      0   \n",
       "\n",
       "     neg    neu    pos  \n",
       "0  0.115  0.692  0.192  \n",
       "1  0.000  0.902  0.098  \n",
       "2  0.107  0.687  0.206  \n",
       "3  0.000  0.606  0.394  \n",
       "4  0.000  1.000  0.000  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'max_depth':[100,250,500],\n",
    "#               'n_estimators':[100,250,400],\n",
    "#               'min_samples_leaf':[2,5,10],\n",
    "#               'min_samples_split':[5,10,15]\n",
    "#               }\n",
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# scorer = make_scorer(f1_score, average = 'weighted')\n",
    "# clf = GridSearchCV(rf, parameters, scoring=scorer, cv=10)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# clf.best_params_\n",
    "\n",
    "# # {'max_depth': 500,\n",
    "# #  'min_samples_leaf': 2,\n",
    "# #  'min_samples_split': 10,\n",
    "# #  'n_estimators': 250}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=500, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=500, min_samples_leaf=2, min_samples_split=10, n_estimators=250, random_state=42)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9507983339118362\n",
      "Testing Accuracy:  0.6724546172059984\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", rf.score(x_train, y_train))\n",
    "print(\"Testing Accuracy: \", rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.64      0.67      0.65       201\n",
      "       false       0.73      0.72      0.73       253\n",
      "   half-true       0.70      0.59      0.64       311\n",
      " mostly-true       0.65      0.64      0.64       245\n",
      "  pants-fire       0.68      0.77      0.72        82\n",
      "        true       0.63      0.75      0.68       175\n",
      "\n",
      "    accuracy                           0.67      1267\n",
      "   macro avg       0.67      0.69      0.68      1267\n",
      "weighted avg       0.67      0.67      0.67      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = rf.predict(x_test)\n",
    "report = classification_report(y_predict, y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extra Tree Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_depth=500, min_samples_leaf=2,\n",
       "                     min_samples_split=10, n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(max_depth=500, min_samples_leaf=2, min_samples_split=10, n_estimators=250, bootstrap=True, random_state=42)\n",
    "et.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9448976049982645\n",
      "Testing Accuracy:  0.6637726913970008\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", et.score(x_train, y_train))\n",
    "print(\"Testing Accuracy: \", et.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.60      0.69      0.64       185\n",
      "       false       0.76      0.69      0.72       272\n",
      "   half-true       0.70      0.57      0.63       324\n",
      " mostly-true       0.63      0.61      0.62       249\n",
      "  pants-fire       0.60      0.86      0.71        64\n",
      "        true       0.63      0.76      0.69       173\n",
      "\n",
      "    accuracy                           0.66      1267\n",
      "   macro avg       0.65      0.70      0.67      1267\n",
      "weighted avg       0.67      0.66      0.66      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = et.predict(x_test)\n",
    "report = classification_report(y_predict, y_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bagging Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=500,\n",
       "                                                        min_samples_leaf=2,\n",
       "                                                        min_samples_split=10),\n",
       "                  n_estimators=250, random_state=42)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_dt = BaggingClassifier(\n",
    "    base_estimator = DecisionTreeClassifier(max_depth=500, min_samples_split=10, min_samples_leaf=2),\n",
    "    n_estimators = 250,\n",
    "    random_state=42\n",
    ")\n",
    "bag_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9723186393613329\n",
      "Testing Accuracy:  0.6550907655880032\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: \", bag_dt.score(x_train, y_train))\n",
    "print(\"Testing Accuracy: \", bag_dt.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " barely-true       0.63      0.63      0.63       213\n",
      "       false       0.69      0.70      0.70       244\n",
      "   half-true       0.67      0.59      0.63       303\n",
      " mostly-true       0.60      0.63      0.62       229\n",
      "  pants-fire       0.76      0.72      0.74        97\n",
      "        true       0.63      0.72      0.67       181\n",
      "\n",
      "    accuracy                           0.66      1267\n",
      "   macro avg       0.66      0.67      0.66      1267\n",
      "weighted avg       0.66      0.66      0.65      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = bag_dt.predict(x_test)\n",
    "report = classification_report(y_predict, y_test)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FakeNewsDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
